#!/usr/bin/env python
# this kernel was based on https://www.kaggle.com/corochann/ashrae-training-lgbm-by-meter-type

import argparse
import gc
from pathlib import Path

import lightgbm as lgb
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.metrics import mean_squared_error
from utils import (
    add_holiyday,
    add_lag_feature,
    add_sg,
    correct_localtime,
    reduce_mem_usage,
    timer,
)

DATA_DIR = Path('../processed')
MODEL_DIR = Path('../models')

parser = argparse.ArgumentParser(description='')
parser.add_argument('--debug', action='store_true', help='debug mode')
args = parser.parse_args()


def train(debug=False):

    # some tuning parameters of models
    black_day = 10  # threshold of removing continuos zero values
    num_rounds = 1000  # num_rounds for lgbm
    folds = 3

    if debug:
        num_rounds = 5

    # # Fast data loading
    with timer("Preprocessing"):

        train_df = pd.read_feather(DATA_DIR / 'train.feather')
        train_df_black = pd.read_feather(DATA_DIR / 'train_black.feather')
        weather_train_df = pd.read_feather(DATA_DIR / 'weather_train.feather')
        building_meta_df = pd.read_feather(DATA_DIR / 'building_metadata.feather')

        # # remove bad buildings

        train_df = train_df[train_df['building_id'] != 1099]

        # # Timezone Correction
        # change wheather meta data localtime to UTC

        correct_localtime(weather_train_df)
        add_holiyday(weather_train_df)

        weather_train_df.head()

        # # Remove continuous zero meter
        # FIXME: UserWarning: Boolean Series key will be reindexed to match DataFrame index.
        train_df = train_df[train_df_black["black_count"] < 24 * black_day]

        del train_df_black
        gc.collect()

        # ## Removing bad data on site_id 0
        #
        # As you can see above, this data looks weired until May 20. It is reported in [this discussion](https://www.kaggle.com/c/ashrae-energy-prediction/discussion/113054#656588) by @barnwellguy that **All electricity meter is 0 until May 20 for site_id == 0**. I will remove these data from training data.
        #
        # It corresponds to `building_id <= 104`.

        train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= "2016-05-20")')
        train_df = train_df.query('not (building_id == 954 & meter_reading == 0)')
        train_df = train_df.query('not (building_id == 1221 & meter_reading == 0)')

        train_df = train_df.reset_index()
        gc.collect()

        # # Site-0 Correction

        # https://www.kaggle.com/c/ashrae-energy-prediction/discussion/119261#latest-684102
        site_0_bids = building_meta_df[building_meta_df.site_id == 0].building_id.unique()
        print(len(site_0_bids), len(train_df[train_df.building_id.isin(site_0_bids)].building_id.unique()))
        # train_df[train_df.building_id.isin(site_0_bids)].head()

        train_df.loc[(train_df.building_id.isin(site_0_bids)) & (train_df.meter == 0), 'meter_reading'] = (
            train_df[(train_df.building_id.isin(site_0_bids)) & (train_df.meter == 0)]['meter_reading']
            * 0.2931
        )

        # train_df[train_df.building_id.isin(site_0_bids)].head()

        # # Data preprocessing
        #
        # Now, Let's try building GBDT (Gradient Boost Decision Tree) model to predict `meter_reading_log1p`.
        # I will try using LightGBM in this notebook.
        train_df['date'] = train_df['timestamp'].dt.date
        train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])

    # # Add time feature
    # Some features introduced in https://www.kaggle.com/ryches/simple-lgbm-solution by @ryches
    #
    # Features that are likely predictive:
    #
    # #### Weather
    #
    # - time of day
    # - holiday
    # - weekend
    # - cloud_coverage + lags
    # - dew_temperature + lags
    # - precip_depth + lags
    # - sea_level_pressure + lags
    # - wind_direction + lags
    # - wind_speed + lags
    #
    # However we should be careful of putting time feature, since we have only 1 year data in training,
    # including `date` makes overfiting to training data.

    def preprocess(df):
        df["hour"] = df["timestamp"].dt.hour
        df["day"] = df["timestamp"].dt.day
        df["weekend"] = df["timestamp"].dt.weekday
        df["month"] = df["timestamp"].dt.month
        df["dayofweek"] = df["timestamp"].dt.dayofweek

    with timer("Feature engineering"):

        preprocess(train_df)

        # # Fill Nan value in weather dataframe by interpolation
        #
        #
        # weather data has a lot of NaNs!!
        #
        # ![](http://)I tried to fill these values by **interpolating** data.

        weather_train_df.info()

        weather_train_df = weather_train_df.groupby('site_id').apply(
            # FIXME: Changed in version 1.1.0:
            # raises ValueError if limit_direction is ‘forward’ or ‘both’ and method is ‘backfill’ or ‘bfill’.
            # raises ValueError if limit_direction is ‘backward’ or ‘both’ and method is ‘pad’ or ‘ffill’.
            # lambda group: group.interpolate(limit_direction='both')
            lambda group: group.interpolate(method="ffill")
        )

        # Seems number of nan has reduced by `interpolate` but some property has never appear in specific `site_id`, and nan remains for these features.

        # ## lags
        #
        # Adding some lag feature

        add_lag_feature(weather_train_df, window=3)
        add_lag_feature(weather_train_df, window=72)

        # # count encoding

        year_map = building_meta_df.year_built.value_counts()
        building_meta_df['year_cnt'] = building_meta_df.year_built.map(year_map)

        bid_map = train_df.building_id.value_counts()
        train_df['bid_cnt'] = train_df.building_id.map(bid_map)

        # categorize primary_use column to reduce memory on merge...
        primary_use_list = building_meta_df['primary_use'].unique()
        primary_use_dict = {key: value for value, key in enumerate(primary_use_list)}
        print('primary_use_dict: ', primary_use_dict)
        building_meta_df['primary_use'] = building_meta_df['primary_use'].map(primary_use_dict)

    gc.collect()

    train_df = reduce_mem_usage(train_df, use_float16=True)
    building_meta_df = reduce_mem_usage(building_meta_df, use_float16=True)
    weather_train_df = reduce_mem_usage(weather_train_df, use_float16=True)

    # # Savitzky–Golay Filter for Weather data

    add_sg(weather_train_df)

    # # Train model

    category_cols = ['building_id', 'site_id', 'primary_use', 'IsHoliday']  # , 'meter'
    feature_cols = (
        ['square_feet', 'year_built']
        + [
            'hour',
            'weekend',
            'day',  # 'month' ,
            # 'dayofweek',
            #    'building_median'
        ]
        + [
            'air_temperature',
            'cloud_coverage',
            'dew_temperature',
            'precip_depth_1_hr',
            'sea_level_pressure',
            # 'wind_direction', 'wind_speed',
            'air_temperature_mean_lag72',
            'air_temperature_max_lag72',
            'air_temperature_min_lag72',
            'air_temperature_std_lag72',
            'cloud_coverage_mean_lag72',
            'dew_temperature_mean_lag72',
            'precip_depth_1_hr_mean_lag72',
            'sea_level_pressure_mean_lag72',
            # 'wind_direction_mean_lag72',
            'wind_speed_mean_lag72',
            'air_temperature_mean_lag3',
            'air_temperature_max_lag3',
            'air_temperature_min_lag3',
            'cloud_coverage_mean_lag3',
            'dew_temperature_mean_lag3',
            'precip_depth_1_hr_mean_lag3',
            'sea_level_pressure_mean_lag3',
            # 'wind_direction_mean_lag3', 'wind_speed_mean_lag3',
            # 'floor_area',
            'year_cnt',
            'bid_cnt',
            'dew_smooth',
            'air_smooth',
            'dew_diff',
            'air_diff',
            'dew_diff2',
            'air_diff2',
        ]
    )

    def create_X_y(train_df, target_meter):
        target_train_df = train_df[train_df['meter'] == target_meter]
        target_train_df = target_train_df.merge(building_meta_df, on='building_id', how='left')
        target_train_df = target_train_df.merge(weather_train_df, on=['site_id', 'timestamp'], how='left')

        X_train = target_train_df[feature_cols + category_cols]
        y_train = target_train_df['meter_reading_log1p'].values

        del target_train_df
        return X_train, y_train

    def fit_lgbm(train, val, devices=(-1,), seed=None, cat_features=None, num_rounds=1500, lr=0.1, bf=0.1):
        """Train Light GBM model"""
        X_train, y_train = train
        X_valid, y_valid = val
        metric = 'l2'
        params = {
            'num_leaves': 31,
            'objective': 'regression',
            # 'max_depth': -1,
            'learning_rate': lr,
            "boosting": "gbdt",
            "bagging_freq": 5,
            "bagging_fraction": bf,
            "feature_fraction": 0.9,
            "metric": metric,
            # "verbosity": -1,
            # 'reg_alpha': 0.1,
            # 'reg_lambda': 0.3
        }
        device = devices[0]
        if device == -1:
            # use cpu
            pass
        else:
            # use gpu
            print(f'using gpu device_id {device}...')
            params.update({'device': 'gpu', 'gpu_device_id': device})

        params['seed'] = seed

        early_stop = 20
        verbose_eval = 20

        d_train = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)
        d_valid = lgb.Dataset(X_valid, label=y_valid, categorical_feature=cat_features)
        watchlist = [d_train, d_valid]

        print('training LGB:')
        # TODO: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future
        # release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.
        model = lgb.train(
            params,
            train_set=d_train,
            num_boost_round=num_rounds,
            valid_sets=watchlist,
            verbose_eval=verbose_eval,
            early_stopping_rounds=early_stop,
        )

        # predictions
        y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)

        print('best_score', model.best_score)
        log = {
            'train/mae': model.best_score['training']['l2'],
            'valid/mae': model.best_score['valid_1']['l2'],
        }
        return model, y_pred_valid, log

    from sklearn.model_selection import GroupKFold

    # seed = 666
    # shuffle = False
    kf = GroupKFold(n_splits=folds)

    # # Train model by each meter type

    def get_groups(df, meter):
        if folds == 12:
            return df[df.meter == meter].month - 1
        elif folds == 6:
            return (df[df.meter == meter].month - 1) // 2
        elif folds == 3:
            return (df[df.meter == meter].month - 1) // 4

    # ## model for meter 0

    oof_total = 0.0
    target_meter = 0

    with timer("Training meter #" + str(target_meter)):

        X_train, y_train = create_X_y(train_df, target_meter=target_meter)
        y_valid_pred_total = np.zeros(X_train.shape[0])
        gc.collect()
        print('target_meter', target_meter, X_train.shape)
        X_train.info()

        cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]
        print('cat_features', cat_features)

        models0 = []

        # for train_idx, valid_idx in kf.split(X_train, y_train):

        for train_idx, valid_idx in kf.split(X_train, y_train, groups=get_groups(train_df, target_meter)):
            train_data = X_train.iloc[train_idx, :], y_train[train_idx]
            valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]

            mindex = train_df[train_df.meter == target_meter].iloc[valid_idx, :].month.unique()
            print(mindex)

            msg = f'Training - train# {len(train_idx)} val# {len(train_idx)}'
            with timer(msg):
                # model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])
                model, y_pred_valid, log = fit_lgbm(
                    train_data, valid_data, cat_features=category_cols, num_rounds=num_rounds, lr=0.05, bf=0.7
                )
            y_valid_pred_total[valid_idx] = y_pred_valid
            models0.append([mindex, model])
            gc.collect()
            if debug:
                break

    oof0 = mean_squared_error(y_train, y_valid_pred_total)

    sns.displot(y_train)
    sns.displot(y_valid_pred_total)

    oof_total += oof0 * len(y_train)

    del X_train, y_train
    gc.collect()

    def plot_feature_importance(model):
        importance_df = pd.DataFrame(
            model[1].feature_importance(), index=feature_cols + category_cols, columns=['importance']
        ).sort_values('importance')
        fig, ax = plt.subplots(figsize=(8, 8))
        importance_df.plot.barh(ax=ax)
        fig.show()

    # ## model for meter 1

    target_meter = 1
    with timer("Training meter #" + str(target_meter)):
        X_train, y_train = create_X_y(train_df, target_meter=target_meter)
        y_valid_pred_total = np.zeros(X_train.shape[0])
        gc.collect()
        print('target_meter', target_meter, X_train.shape)

        cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]
        print('cat_features', cat_features)

        models1 = []

        for train_idx, valid_idx in kf.split(X_train, y_train, groups=get_groups(train_df, target_meter)):
            # for train_idx, valid_idx in kf.split(X_train, y_train):
            train_data = X_train.iloc[train_idx, :], y_train[train_idx]
            valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]

            mindex = train_df[train_df.meter == target_meter].iloc[valid_idx, :].month.unique()

            # print('train', len(train_idx), 'valid', len(valid_idx))
            # model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])
            msg = f'Training - train# {len(train_idx)} val# {len(valid_idx)}'
            with timer(msg):
                model, y_pred_valid, log = fit_lgbm(
                    train_data, valid_data, cat_features=category_cols, num_rounds=num_rounds, lr=0.05, bf=0.5
                )
            y_valid_pred_total[valid_idx] = y_pred_valid
            models1.append([mindex, model])
            gc.collect()
            if debug:
                break

    oof1 = mean_squared_error(y_train, y_valid_pred_total)

    sns.displot(y_train)
    sns.displot(y_valid_pred_total)

    oof_total += oof1 * len(y_train)

    del X_train, y_train
    gc.collect()

    # ## model for meter 2

    target_meter = 2
    with timer("Training meter #" + str(target_meter)):
        X_train, y_train = create_X_y(train_df, target_meter=target_meter)
        y_valid_pred_total = np.zeros(X_train.shape[0])

        gc.collect()
        print('target_meter', target_meter, X_train.shape)

        cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]
        print('cat_features', cat_features)

        models2 = []

        for train_idx, valid_idx in kf.split(X_train, y_train, groups=get_groups(train_df, target_meter)):
            # for train_idx, valid_idx in kf.split(X_train, y_train):
            train_data = X_train.iloc[train_idx, :], y_train[train_idx]
            valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]

            mindex = train_df[train_df.meter == target_meter].iloc[valid_idx, :].month.unique()
            # print('train', len(train_idx), 'valid', len(valid_idx))
            # model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])
            msg = f'Training - train# {len(train_idx)} val# {len(valid_idx)}'
            with timer(msg):
                model, y_pred_valid, log = fit_lgbm(
                    train_data, valid_data, cat_features=category_cols, num_rounds=num_rounds, lr=0.05, bf=0.8
                )
            y_valid_pred_total[valid_idx] = y_pred_valid
            models2.append([mindex, model])
            gc.collect()
            if debug:
                break

    oof2 = mean_squared_error(y_train, y_valid_pred_total)

    oof_total += oof2 * len(y_train)

    sns.displot(y_train)
    sns.displot(y_valid_pred_total)

    del X_train, y_train
    gc.collect()

    # ## model for meter 3

    target_meter = 3
    with timer("Training meter #" + str(target_meter)):
        X_train, y_train = create_X_y(train_df, target_meter=target_meter)
        y_valid_pred_total = np.zeros(X_train.shape[0])

        gc.collect()
        print('target_meter', target_meter, X_train.shape)

        cat_features = [X_train.columns.get_loc(cat_col) for cat_col in category_cols]
        print('cat_features', cat_features)

        models3 = []

        for train_idx, valid_idx in kf.split(X_train, y_train, groups=get_groups(train_df, target_meter)):
            # for train_idx, valid_idx in kf.split(X_train, y_train):
            train_data = X_train.iloc[train_idx, :], y_train[train_idx]
            valid_data = X_train.iloc[valid_idx, :], y_train[valid_idx]

            mindex = train_df[train_df.meter == target_meter].iloc[valid_idx, :].month.unique()
            # print('train', len(train_idx), 'valid', len(valid_idx))
            # model, y_pred_valid, log = fit_cb(train_data, valid_data, cat_features=cat_features, devices=[0,])
            msg = f'Training - train# {len(train_idx)} val# {len(valid_idx)}'
            with timer(msg):
                model, y_pred_valid, log = fit_lgbm(
                    train_data, valid_data, cat_features=category_cols, num_rounds=num_rounds, lr=0.03, bf=0.9
                )
            y_valid_pred_total[valid_idx] = y_pred_valid
            models3.append([mindex, model])
            gc.collect()
            if debug:
                break

    oof3 = mean_squared_error(y_train, y_valid_pred_total)

    oof_total += oof3 * len(y_train)

    oof_total = oof_total / len(train_df)

    sns.displot(y_train)
    sns.displot(y_valid_pred_total)

    del X_train, y_train
    gc.collect()

    # # OOF MSE

    print('oof0=', np.sqrt(oof0))
    print('oof1=', np.sqrt(oof1))
    print('oof2=', np.sqrt(oof2))
    print('oof3=', np.sqrt(oof3))
    print('total=', np.sqrt(oof_total))

    # # Save Models
    if not debug:
        import pickle

        with open(MODEL_DIR / 'meter_split_model.pickle', mode='wb') as f:
            pickle.dump([models0, models1, models2, models3, bid_map], f)


if __name__ == '__main__':
    debug = args.debug
    print('debug=', debug)

    train(debug)
